"""
search.py (FINAL STABLE)
--------------------------------------------------
âœ… FAISS index preload (startup)
âœ… SigLIP embedding ì‚¬ìš©
âœ… ê·¸ë£¹ í‰ê·  ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰
âœ… cosine similarity ê¸°ì¤€
âœ… threshold ê¸°ë°˜ ë§¤ì¹­ íŒì •
âœ… Node ì„œë²„ ì—°ë™ìš© ì•ˆì • ì‘ë‹µ êµ¬ì¡°
âœ… ğŸ”¥ group-search ìƒì„¸ ë¡œê·¸ ì¶”ê°€ (í›„ë³´ / score / íŒì •)
"""

import os
import logging
import numpy as np
import faiss
from PIL import Image

from siglip import image_to_vector


# ==================================================
# Logger
# ==================================================
logger = logging.getLogger(__name__)


# ==================================================
# Path Config
# ==================================================

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

INDEX_PATH = os.path.join(BASE_DIR, "index", "siglip.index")
IDS_PATH = os.path.join(BASE_DIR, "index", "product_ids.npy")


# ==================================================
# Search Config (ğŸ”¥ ì‹¤ì„œë¹„ìŠ¤ ê¸°ì¤€)
# ==================================================

# cosine similarity ê¸°ì¤€
SIMILARITY_THRESHOLD = 0.3
TOP_K = 5


# ==================================================
# Load Assets (1íšŒ)
# ==================================================

def _load_assets():
    if not os.path.exists(INDEX_PATH):
        raise FileNotFoundError(f"FAISS index not found: {INDEX_PATH}")

    if not os.path.exists(IDS_PATH):
        raise FileNotFoundError(f"product_ids not found: {IDS_PATH}")

    index = faiss.read_index(INDEX_PATH)
    product_ids = np.load(IDS_PATH, allow_pickle=True)

    if index.ntotal != len(product_ids):
        raise RuntimeError("Index size and product_ids length mismatch")

    logger.info(
        "[FAISS] index loaded (total_groups=%d)",
        index.ntotal,
    )

    return index, product_ids


# ğŸ”¥ ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ë¡œë“œ
INDEX, PRODUCT_IDS = _load_assets()


# ==================================================
# ì „ì²´ DB ê²€ìƒ‰ (ê¸°ì¡´ ìœ ì§€ âŒ ë³€ê²½ ê¸ˆì§€)
# ==================================================

def search_image(image_path: str, top_k: int = TOP_K):
    img = Image.open(image_path).convert("RGB")
    q = image_to_vector(img).reshape(1, -1)

    sims, idxs = INDEX.search(q, top_k)

    results = []

    for sim, idx in zip(sims[0], idxs[0]):
        if idx < 0:
            continue

        pid = PRODUCT_IDS[int(idx)]
        similarity = float(sim)
        distance = float(1.0 - similarity)

        results.append({
            "product_id": str(pid),
            "similarity": similarity,
            "distance": distance,
        })

    if not results:
        return {
            "matched": False,
            "best": None,
            "results": [],
        }

    best = results[0]

    if best["similarity"] < SIMILARITY_THRESHOLD:
        return {
            "matched": False,
            "best": best,
            "results": results,
        }

    return {
        "matched": True,
        "best": best,
        "results": results,
    }


# ==================================================
# ğŸ”¥ ì‚¬ìš©ì íŒŒìš°ì¹˜ ê·¸ë£¹ ê²€ìƒ‰ (Node ì—°ë™ìš©)
# ==================================================

def search_image_with_groups(
    image_path: str,
    groups: dict,
):
    """
    image_path: ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ê²½ë¡œ
    groups: {
        "12": ["s3Key1", "s3Key2"],
        "15": ["s3Key3", "s3Key4"]
    }

    return:
    {
        "matched": bool,
        "group_id": str | None,
        "score": float | None
    }
    """

    logger.info(
        "[GROUP_SEARCH][START] groups=%d image=%s",
        len(groups),
        os.path.basename(image_path),
    )

    # ------------------------------
    # 1ï¸âƒ£ query embedding
    # ------------------------------
    img = Image.open(image_path).convert("RGB")
    q = image_to_vector(img)

    best_group_id = None
    best_score = -1.0

    # ------------------------------
    # 2ï¸âƒ£ ê·¸ë£¹ë³„ í‰ê·  ë²¡í„°ì™€ cosine similarity
    # ------------------------------
    for group_id, image_keys in groups.items():
        vectors = []

        for key in image_keys:
            try:
                # âš ï¸ build_indexì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ
                # S3 ì´ë¯¸ì§€ë“¤ì€ ì´ë¯¸ indexì— ë°˜ì˜ë¨
                # ì—¬ê¸°ì„œëŠ” group_id ê¸°ì¤€ ë¹„êµë§Œ ìˆ˜í–‰
                idxs = np.where(PRODUCT_IDS == str(group_id))[0]
                if len(idxs) == 0:
                    continue

                vec = INDEX.reconstruct(int(idxs[0]))
                vectors.append(vec)

            except Exception as e:
                logger.warning(
                    "[GROUP_SEARCH][WARN] group=%s key=%s error=%s",
                    group_id,
                    key,
                    str(e),
                )

        if not vectors:
            logger.debug(
                "[GROUP_SEARCH][SKIP] group=%s no vectors",
                group_id,
            )
            continue

        group_vec = np.mean(vectors, axis=0)
        group_vec = group_vec / np.linalg.norm(group_vec)

        score = float(np.dot(q, group_vec))

        logger.debug(
            "[GROUP_SEARCH][CANDIDATE] group=%s score=%.4f",
            group_id,
            score,
        )

        if score > best_score:
            best_score = score
            best_group_id = group_id

    # ------------------------------
    # 3ï¸âƒ£ íŒì •
    # ------------------------------
    matched = best_score >= SIMILARITY_THRESHOLD

    logger.info(
        "[GROUP_SEARCH][RESULT] matched=%s group=%s score=%.4f threshold=%.2f",
        matched,
        best_group_id,
        best_score,
        SIMILARITY_THRESHOLD,
    )

    if not matched:
        return {
            "matched": False,
            "group_id": None,
            "score": best_score,
        }

    return {
        "matched": True,
        "group_id": best_group_id,
        "score": best_score,
    }
