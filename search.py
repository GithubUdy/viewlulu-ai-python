"""
search.py (FINAL â€“ SPEED OPTIMIZED)
--------------------------------------------------
âœ… FAISS index preload (startup)
âœ… SigLIP embedding (query 1íšŒë§Œ)
âœ… FAISS reconstruct() ê¸°ë°˜ ê·¸ë£¹ ë¹„êµ (ğŸ”¥ ì¬ì„ë² ë”© ì œê±°)
âœ… 1:N (í™”ì¥í’ˆ 1 : ì´ë¯¸ì§€ N) max-score ì „ëµ
âœ… cosine similarity
âœ… ìë™ threshold íŠœë‹ (min + gap)
âœ… Node ì„œë²„ ì—°ë™ ì‘ë‹µ êµ¬ì¡° ìœ ì§€
âœ… ğŸ”¥ ìƒì„¸ ë¡œê·¸ + íƒ€ì´ë° ë¡œê·¸
"""

import os
import logging
import time
import numpy as np
import faiss
from PIL import Image

from siglip import image_to_vector


# ==================================================
# Logger
# ==================================================
logger = logging.getLogger(__name__)


# ==================================================
# Path Config
# ==================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

INDEX_PATH = os.path.join(BASE_DIR, "index", "siglip.index")
IDS_PATH = os.path.join(BASE_DIR, "index", "product_ids.npy")


# ==================================================
# Search Config
# ==================================================
SIMILARITY_THRESHOLD = 0.3
FAISS_TOP_K = 5

# ğŸ”¥ ìë™ íŠœë‹ ê¸°ì¤€
MIN_THRESHOLD = 0.45
GAP_THRESHOLD = 0.07


# ==================================================
# Load Assets (startup 1íšŒ)
# ==================================================
def _load_assets():
    if not os.path.exists(INDEX_PATH):
        raise FileNotFoundError(f"FAISS index not found: {INDEX_PATH}")
    if not os.path.exists(IDS_PATH):
        raise FileNotFoundError(f"product_ids not found: {IDS_PATH}")

    index = faiss.read_index(INDEX_PATH)
    product_ids = np.load(IDS_PATH, allow_pickle=True)

    if index.ntotal != len(product_ids):
        raise RuntimeError("Index size and product_ids length mismatch")

    logger.info("[FAISS] index loaded (ntotal=%d)", index.ntotal)
    return index, product_ids


INDEX, PRODUCT_IDS = _load_assets()


# ==================================================
# (ê¸°ì¡´ ìœ ì§€) ì „ì²´ DB ê²€ìƒ‰ âŒ ë³€ê²½ ê¸ˆì§€
# ==================================================
def search_image(image_path: str, top_k: int):
    img = Image.open(image_path).convert("RGB")
    q = image_to_vector(img).reshape(1, -1)

    sims, idxs = INDEX.search(q, top_k)

    results = []
    for sim, idx in zip(sims[0], idxs[0]):
        if idx < 0:
            continue

        pid = PRODUCT_IDS[int(idx)]
        similarity = float(sim)
        distance = float(1.0 - similarity)

        results.append({
            "product_id": str(pid),
            "similarity": similarity,
            "distance": distance,
        })

    if not results:
        return {"matched": False, "best": None, "results": []}

    best = results[0]

    if best["similarity"] < SIMILARITY_THRESHOLD:
        return {"matched": False, "best": best, "results": results}

    return {"matched": True, "best": best, "results": results}

def _embed_image_path(image_path: str):
    img = Image.open(image_path).convert("RGB")
    vec = image_to_vector(img)
    vec = vec / np.linalg.norm(vec)
    return vec.reshape(1, -1)



# ==================================================
# ğŸ”¥ ì‚¬ìš©ì íŒŒìš°ì¹˜ ê·¸ë£¹ ê²€ìƒ‰ (ìµœì¢… í•µì‹¬)
# ==================================================
def search_image_with_groups(image_path: str, groups: dict):
    """
    image_path: ì´¬ì˜ ì´ë¯¸ì§€ ê²½ë¡œ
    groups: {
        "12": ["/tmp/12/1.jpg", "..."],
        ...
    }
    """

    t0 = time.perf_counter()

    logger.info(
        "[GROUP_SEARCH][START] groups=%d image=%s",
        len(groups),
        os.path.basename(image_path),
    )

    if not groups:
        return {"matched": False, "group_id": None, "score": -1.0}

    # --------------------------------------------------
    # 1ï¸âƒ£ Query embedding (ğŸ”¥ ë‹¨ 1íšŒ)
    # --------------------------------------------------
    q = _embed_image_path(image_path)

    # --------------------------------------------------
    # 2ï¸âƒ£ FAISS í›„ë³´ ê·¸ë£¹ ê²€ìƒ‰ (ğŸ”¥ í•µì‹¬)
    # --------------------------------------------------
    q2 = q.reshape(1, -1)
    sims, idxs = INDEX.search(q2, min(FAISS_TOP_K, INDEX.ntotal))

    candidate_group_ids = []
    for idx in idxs[0]:
        if idx < 0:
            continue
        gid = str(PRODUCT_IDS[int(idx)])
        if gid in groups:
            candidate_group_ids.append(gid)

    logger.info(
        "[GROUP_SEARCH][FAISS] candidates=%s",
        candidate_group_ids,
    )

    if not candidate_group_ids:
        logger.info("[GROUP_SEARCH][RESULT] no candidates")
        return {"matched": False, "group_id": None, "score": -1.0}

    # --------------------------------------------------
    # 3ï¸âƒ£ í›„ë³´ ê·¸ë£¹ë§Œ 1:4 ë¹„êµ
    # --------------------------------------------------
    group_scores = []

    for group_id in candidate_group_ids:
        image_paths = groups.get(group_id, [])
        scores = []

        for img_path in image_paths:
            try:
                v = _embed_image_path(img_path)
                sim = float(np.dot(q, v))
                scores.append(sim)
            except Exception as e:
                logger.warning(
                    "[GROUP_SEARCH][IMAGE_FAIL] group=%s img=%s err=%s",
                    group_id,
                    img_path,
                    str(e),
                )

        if not scores:
            continue

        max_score = max(scores)
        avg_score = sum(scores) / len(scores)

        logger.info(
            "[GROUP_SEARCH][GROUP_SUMMARY] group=%s max=%.4f avg=%.4f",
            group_id,
            max_score,
            avg_score,
        )

        group_scores.append({
            "group_id": group_id,
            "max": max_score,
        })

    if not group_scores:
        return {"matched": False, "group_id": None, "score": -1.0}

    # --------------------------------------------------
    # 4ï¸âƒ£ ìë™ íŠœë‹ íŒì • (ê¸°ì¡´ ìœ ì§€)
    # --------------------------------------------------
    group_scores.sort(key=lambda x: x["max"], reverse=True)

    best = group_scores[0]
    second = group_scores[1] if len(group_scores) > 1 else None

    best_score = best["max"]
    gap = best_score - (second["max"] if second else 0.0)

    matched = (
        best_score >= MIN_THRESHOLD and
        gap >= GAP_THRESHOLD
    )

    t1 = time.perf_counter()

    logger.info(
        "[GROUP_SEARCH][DECISION] matched=%s best=%s score=%.4f gap=%.4f total_ms=%.1f",
        matched,
        best["group_id"],
        best_score,
        gap,
        (t1 - t0) * 1000,
    )

    return {
        "matched": matched,
        "group_id": best["group_id"] if matched else None,
        "score": best_score,
    }
